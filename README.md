# ğŸ›ï¸ Amazon-Like Semantic Eâ€‘Commerce Recommender System

## ğŸ“˜ Project Overview
A fullâ€‘stack **AIâ€‘powered eâ€‘commerce search and recommendation engine** inspired by Amazon ğŸ§ .

It scrapes real product data using Selenium & BeautifulSoup, builds a **semantic understanding model** (using Sentenceâ€‘BERT), and serves intelligent product recommendations through a Flask backend and a Bootstrapâ€‘based frontend that visually resembles Amazon.

---

## ğŸš€ Features
- **Web Scraping:** Automated product extraction from Amazon using Selenium + BeautifulSoup.
- **Data Engineering:** Cleaned & merged all categoryâ€‘wise CSVs into a single master dataset.
- **Semantic Search:** Deep learning via SentenceTransformer for intelligent textâ€“product matching.
- **Smart Ranking:** Cosine similarity to find contextually closest products.
- **Frontend Design:** HTML + CSS + Bootstrap for a clean, Amazonâ€‘style interface.
- **Flask Backend:** RESTâ€‘based architecture to serve realâ€‘time search results.
- **Modular Design:** Twoâ€‘script architecture for ease of debugging and updates.

---

## ğŸ§  Model & Training

### Model Used
`SentenceTransformer` â†’ **allâ€‘MiniLMâ€‘L6â€‘v2**

### Why This Model?
- Compact and fast transformer model by HuggingFace.
- Learns semantic meaning â€” â€œphones under 50000â€ â‰ˆ â€œmobiles below 50k.â€
- Built for sentence similarity and recommendation tasks.

### Algorithm Used
**Cosine Similarity** for ranking embeddings:
\[
\text{similarity}(A,B) = \frac{A \cdot B}{||A|| \times ||B||}
\]

### Model Workflow
1. Each product title â†’ vector embedding (1024â€‘dimensional numeric representation).
2. User query â†’ encoded using the same model.
3. Cosine similarity calculated between query and all products.
4. Products sorted by relevance score.
5. Flask backend returns top K matching products to the frontend.

---

## ğŸ’» Tech Stack

| Layer | Tools Used |
|--------|-------------|
| Web Scraping | Selenium, BeautifulSoup |
| Data Cleaning | pandas, NumPy |
| ML/NLP | SentenceTransformers, Scikitâ€‘learn, RapidFuzz |
| Backend | Flask |
| Frontend | HTML, CSS, Bootstrap |
| Deployment | Render / PythonAnywhere (Free Tier) |

---

## âš™ï¸ How To Run the Project

### 1ï¸âƒ£ Clone the Repository
git clone https://github.com/AfzalSurti/AmazonRecommender
cd Amazon-Web-Scrapper

### 2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

Amazon_Recommender/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # CSVs scraped from Amazon (e.g., laptops_products.csv)
â”‚   â”œâ”€â”€ processed/            # Cleaned & merged CSVs stored here
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ tfidf_model.pkl       # TF-IDF model file
â”‚   â”œâ”€â”€ cosine_sim.npy        # Similarity matrix
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 1_data_preprocessing.py
â”‚   â”œâ”€â”€ 2_train_model.py
â”‚   â”œâ”€â”€ 3_test_recommender.py
â”‚
â”œâ”€â”€ scrapping/
|   â”œâ”€â”€ scrapping_all_products.py
|
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ recommendations.csv   # Output examples of the model
â”‚
â”œâ”€â”€ templates/                # Frontend
â”‚   â”œâ”€â”€index.html
|   â”œâ”€â”€product.html
|
â”œâ”€â”€app_symentic.py - main backend logic
â”œâ”€â”€ requirements.txt          # Project dependencies
â”œâ”€â”€ README.md                 # Documentation


data- it has two folders 
      1-raw - a raw datsets that is a amazon data categories wise that i   genrate using the selenium , bs4 .
      2-processed -  then i merged it all raw datasets which are categorie wise

models- I take  a model "all-MiniLM-L6-v2" and train on that products_master.csv dataset
        and compute embeddings and save artifacts in a models/.

results - after training i have to check model is working or not so 
          i run 3_test_recommender_symentic.py and it genrates the output in a results/recommendatios.csv.

scapping - in a scraping theres a script scrapping_all_products.py its a script to 
            get product from amazon site categori wise.

scripts - in a scripts folder there are 3 scripts one for merging , one for training , 
          one for testing  , and one script is for adding categori column in a master datset.

templates - contains frontend file index.html - home page and product.html - product 
            display page .

app_symentic.py - main backend logic is there using flask first load the model 
                  and interprets the input and give corrosponding output and also routings are there.

Procfile - i have to deploye this on render so server sould know which commands to run so 
            i put that command in it.

### 4ï¸âƒ£ Run Flask App
python app_symentic.py


Your app will now run on:
[http://127.0.0.1:5000](http://127.0.0.1:5000)

---

## ğŸ”§ Important Notes
- Install **Flask** and **transformers** only â€” other dependencies will autoâ€‘install.
- Run those **two core scripts** separately:  
  - The data/model preparation script  
  - The main Flask file `app_symentic.py`
- Avoid running the merger file directly (due to GitHub file size restrictions).
- After setup, only one command is needed for execution: python app_symentic.py

---

## ğŸ—ï¸ Future Enhancements
- Add subâ€‘categories like:
- Mobiles â†’ iPhones, Samsung, Realme
- Clothing â†’ Menâ€‘Tâ€‘Shirts, Womenâ€‘Tops
- Integrate Flipkart, Meesho, and Myntra scrapers for crossâ€‘platform results.
- Build advanced query understanding with NER or fineâ€‘tuned T5.
- Add online deployment with persistent DB.

---

## ğŸ“„ Dependencies
Read  `requirements.txt` 

---

## ğŸ§  What Youâ€™ll Learn
- How modern eâ€‘commerce recommendation systems understand intent.
- How to apply transformer models for semantic understanding.
- Building scalable fullâ€‘stack AI products with Flask.

---

## âœ¨ Author
Developed by **Afzal Nasirbhai Surti**

LinkedIn:  https://www.linkedin.com/in/afzal-surti-9904b2287/
GitHub: https://github.com/AfzalSurti

---

ğŸ›’ *A realâ€‘world AI + Web Development project made to demonstrate handsâ€‘on NLP for product recommendation.*

